# needs at least 16 GB of memory

exp_name: test_if_work_4
work_dir: /home/day3/cxx/codefield/MyBasicVSR/work_dir
num_gpu: auto

train_dataloader:
  batch_size: 4
  shuffle: True
  num_workers: 0
  pin_memory: True
  dataset:
    type: REDSDataset
    gt_dir: /home/day3/cxx/codefield/MyBasicVSR/data/REDS/train_sharp
    lq_dir: /home/day3/cxx/codefield/MyBasicVSR/data/REDS/train_sharp_bicubic/X4
    scale_factor: 4
    patch_size: 64
    num_input_frames: 15
    filename_tmpl: "{:08d}.png"
    max_keys: 270
    val_partition: REDS4
    is_test: False

val_dataloader:
  batch_size: 1
  shuffle: False
  num_workers: 0
  pin_memory: True
  dataset:
    type: REDSDataset
    gt_dir: /home/day3/cxx/codefield/MyBasicVSR/data/REDS/train_sharp
    lq_dir: /home/day3/cxx/codefield/MyBasicVSR/data/REDS/train_sharp_bicubic/X4
    scale_factor: 4
    patch_size: 64
    num_input_frames: 100
    filename_tmpl: "{:08d}.png"
    max_keys: 270
    val_partition: REDS4
    is_test: True

model:
  type: BaseVSRModel
  backbone:
    type: BasicVSR
    scale_factor: 4
    mid_channels: 64
    num_blocks: 30
    spynet_pretrained: /home/day3/cxx/codefield/MyBasicVSR/checkpoint/spynet_20210409-c6c1bd09.pth
  pretrained: ~

train:
  ema_decay: 0.999
  optimizer:
    type: Adam
    lr: !!float 2e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: CosineAnnealingLR
    T_max: 300000
    eta_min: !!float 1e-7

  total_iter: 300000
  warmup_iter: -1 # no warm up
  fix_flow: 5000
  flow_lr_mul: 0.125

  criterion:
    type: CharbonnierLoss
    loss_weight: 1.0
    reduction: mean

  # pixel_loss:
  #   type: CharbonnierLoss
  #   loss_weight: 1.0
  #   reduction: mean
  # train_cfg:
  #   fix_iter: 5000
  # data_preprocessor:
  #   type: EditDataPreprocessor
  #   mean: [0., 0., 0.]
  #   std: [255., 255., 255.]
# val_evaluator = dict(
#     type='EditEvaluator', metrics=[
#         dict(type='PSNR'),
#         dict(type='SSIM'),
#     ])

# train_cfg = dict(
#     type='IterBasedTrainLoop', max_iters=300_000, val_interval=5000)
# val_cfg = dict(type='EditValLoop')

# # optimizer
# optim_wrapper = dict(
#     constructor='DefaultOptimWrapperConstructor',
#     type='OptimWrapper',
#     optimizer=dict(type='Adam', lr=2e-4, betas=(0.9, 0.99)),
#     paramwise_cfg=dict(custom_keys={'spynet': dict(lr_mult=0.125)}))

# default_hooks = dict(checkpoint=dict(out_dir=save_dir))

# # learning policy
# param_scheduler = dict(
#     type='CosineRestartLR',
#     by_epoch=False,
#     periods=[300000],
#     restart_weights=[1],
#     eta_min=1e-7)

# find_unused_parameters = True
